# llama3_text_skill_grpo.yaml
# --------------------------------------------------------------
# Hyper-parameters for fine-tuning Meta-Llama-3.1-70B on the
# CRMArena-Pro B2B *text-skill* tasks with GRPO + LoRA PEFT.
# This file will be consumed by train_text_skill.py via
#   GRPOConfig.from_yaml("configs/llama3_text_skill_grpo.yaml")
# --------------------------------------------------------------

# ---- model / tokenizer -----------------------------------------------------
model_name: Qwen/Qwen3-14B
trust_remote_code: true

# ---- training batch sizes --------------------------------------------------
# Updated for 4×H100 (GPUs 0-1 for training, TP=2)
per_device_train_batch_size: 2        # 2 seq / GPU → 4 seq total on each GPU
gradient_accumulation_steps: 4        # effective 8 seq per step
num_train_epochs: 2
max_steps: -1                         # use epochs

# keep a small head-room so multi-turn dialogs never exceed 8 192 tokens
max_prompt_length: 8000

# ---- logging & evaluation --------------------------------------------------
logging_steps: 5
log_completions: true
num_completions_to_print: 4 
save_steps: 50                       # save model checkpoint every 50 steps
evaluation_strategy: steps
eval_steps: 50                       # run validation every 50 optimisation steps (~0.1 epoch)

# ---- optimisation ----------------------------------------------------------
learning_rate: 5.0e-5
lr_scheduler_type: cosine
warmup_ratio: 0.05
adam_beta1: 0.9
adam_beta2: 0.95
adam_epsilon: 1.0e-8
max_grad_norm: 1.0

# ---- LoRA settings ---------------------------------------------------------
peft:
  lora_r: 64
  lora_alpha: 128
  lora_dropout: 0.05
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj

# ---- Reward normalisation --------------------------------------------------
# enables moving average baseline & scaling inside GRPOTrainer
normalize_rewards: true

# ---- DeepSpeed ZeRO-3 ------------------------------------------------------
deepspeed_config:
  stage: 3
  offload_optimizer_device: cpu
  offload_param_device: none
  reduce_scatter: true
  overlap_comm: true
  allgather_bucket_size: 400000000
  reduce_bucket_size:   400000000

# ---- async generation ------------------------------------------------------
num_batches_ahead: 0                  # keep one batch in flight via vLLM
async_generation_timeout: 3600.0
max_concurrent: 128  # allow up to 1 hour for long multi-turn rollouts

# push updated policy weights to vLLM only every 10 optimiser steps
weight_sync_steps: 50

# ---- W&B -------------------------------------------------------------------
report_to: wandb
wandb_project: crmarena_text_skill
wandb_run_name: qwen3_14b_b2b_grpo 